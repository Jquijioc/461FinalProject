{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "#get current directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# add crop to the directory\n",
    "base_dir = os.path.join(base_dir, 'crop')\n",
    "\n",
    "dataset = ImageFolder(root=base_dir, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training and testing data\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) 25\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print(image.size(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the classes for the aircraft\n",
    "class_names = [\"A-10\", \"A-400M\", \"AG-600\", \"AH-64\", \"AV-8B\", \"An-124\", \"An-22\", \"An-225\", \"An-72\", \"B-1\", \"B-2\", \"B-21\", \"B-52\", \"Be-200\", \"C-130\", \"C-17\", \"C-2\", \"C-390\", \"C-5\", \"CH-47\", \"CL-415\", \"E-2\", \"E-7\", \"EF-2000\", \"F-117\", \"F-14\", \"F-15\", \"F-16\", \"F-22\", \"F-35\", \"F-4\", \"F/A-18\", \"H-6\", \"J-10\", \"J-20\", \"JAS-39\", \"JF-17\", \"JH-7\", \"KC-135\", \"KF-21\", \"KJ-600\", \"Ka-27\", \"Ka-52\", \"MQ-9\", \"Mi-24\", \"Mi-26\", \"Mi-28\", \"Mig-29\", \"Mig-31\", \"Mirage2000\", \"P-3\", \"RQ-4\", \"Rafale\", \"SR-71\", \"Su-24\", \"Su-25\", \"Su-34\", \"Su-57\", \"TB-001\", \"TB-2\", \"Tornado\", \"Tu-160\", \"Tu-22M\", \"Tu-95\", \"U-2\", \"UH-60\", \"US-2\", \"V-22\", \"Vulcan\", \"WZ-7\", \"XB-70\", \"Y-20\", \"YF-23\", \"Z-19\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # new shape is 6 * 252 * 252\n",
    "        self.pool = nn.MaxPool2d(2, 2) # new shape is 6 * 126 * 126\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # new shape is 16 * 122 * 122\n",
    "        self.fc1 = nn.Linear(16 * 61 * 61, 120) # flatten the image to 16 * 61 * 61\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 74) # change the output features to 74\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 61 * 61)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)  # Increased learning rate from 0.001 to 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "Loss:  4.0135\n",
      "Training epoch 2\n",
      "Loss:  3.7932\n",
      "Training epoch 3\n",
      "Loss:  3.4933\n",
      "Training epoch 4\n",
      "Loss:  3.0291\n",
      "Training epoch 5\n",
      "Loss:  2.4722\n",
      "Training epoch 6\n",
      "Loss:  1.8325\n",
      "Training epoch 7\n",
      "Loss:  1.2630\n",
      "Training epoch 8\n",
      "Loss:  0.8843\n",
      "Training epoch 9\n",
      "Loss:  0.6821\n",
      "Training epoch 10\n",
      "Loss:  0.5454\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f'Training epoch {epoch + 1}')\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Loss: {running_loss / len(train_loader): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.68%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accruacy = correct / total\n",
    "print(f'Accuracy: {accruacy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
